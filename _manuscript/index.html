<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Deep Learning Paper Review</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>


<meta name="citation_title" content="Deep Learning Paper Review">
<meta name="citation_author" content="Shauna Heron">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Combining clinical notes with structured electronic health records enhances the prediction of mental health crises;,citation_author=Roger Garriga;,citation_author=Teodora Sandra Buda;,citation_author=João Guerreiro;,citation_author=Jesús Omaña Iglesias;,citation_author=Iñaki Estella Aguerri;,citation_author=Aleksandar Matić;,citation_publication_date=2023-11-21;,citation_cover_date=2023-11-21;,citation_year=2023;,citation_fulltext_html_url=https://www.cell.com/cell-reports-medicine/abstract/S2666-3791(23)00437-8;,citation_issue=11;,citation_doi=10.1016/j.xcrm.2023.101260;,citation_volume=4;,citation_language=en-US;,citation_journal_title=Cell Reports Medicine;">
<meta name="citation_reference" content="citation_title=Addressing urgent workforce challenges in child and youth mental health;,citation_author=undefined CMHO;,citation_publication_date=2022-03;,citation_cover_date=2022-03;,citation_year=2022;">
<meta name="citation_reference" content="citation_title=Machine learning model to predict mental health crises from electronic health records;,citation_author=Roger Garriga;,citation_author=Javier Mas;,citation_author=Semhar Abraha;,citation_author=Jon Nolan;,citation_author=Oliver Harrison;,citation_author=George Tadros;,citation_author=Aleksandar Matic;,citation_publication_date=2022-06;,citation_cover_date=2022-06;,citation_year=2022;,citation_fulltext_html_url=https://www.nature.com/articles/s41591-022-01811-5;,citation_issue=6;,citation_doi=10.1038/s41591-022-01811-5;,citation_volume=28;,citation_language=en;,citation_journal_title=Nature Medicine;">
<meta name="citation_reference" content="citation_title=Measuring Performance: AUPRC and Average Precision;,citation_publication_date=2019-03-02;,citation_cover_date=2019-03-02;,citation_year=2019;,citation_fulltext_html_url=https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/;,citation_language=en;">
<meta name="citation_reference" content="citation_title=Machine Learning / Deep Learning - Classifier Evaluation Slides;,citation_author=Meng Cheng Lau;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_language=en;,citation_publisher=Laurentian University;">
<meta name="citation_reference" content="citation_title=Machine Learning / Deep Learning - Neural Network Slides;,citation_author=Meng Cheng Lau;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_language=en;,citation_publisher=Laurentian University;">
<meta name="citation_reference" content="citation_title=BERT 101 - state of the art NLP model explained;,citation_fulltext_html_url=https://huggingface.co/blog/bert-101;">
<meta name="citation_reference" content="citation_title=Welcome to the SHAP documentation  SHAP latest documentation;,citation_fulltext_html_url=https://shap.readthedocs.io/en/latest/;">
<meta name="citation_reference" content="citation_title=Mental health hospitalizations in canadian children, adolescents, and young adults over the COVID-19 pandemic;,citation_author=Nadia Roumeliotis;,citation_author=Matthew Carwana;,citation_author=Ofélie Trudeau;,citation_author=Katia Charland;,citation_author=Kate Zinszer;,citation_author=Mike Benigeri;,citation_author=Mamadou Diop;,citation_author=Jesse Papenburg;,citation_author=Samina Ali;,citation_author=Maryna Yaskina;,citation_author=Gita Wahi;,citation_author=Baudoin Forgeot d’Arc;,citation_author=Sylvana Côté;,citation_author=Manish Sadarangani;,citation_author=Nicole E. Basta;,citation_author=Patricia S. Fontela;,citation_author=Soren Gantt;,citation_author=Terry P. Klassen;,citation_author=Caroline Quach;,citation_author=Quynh Doan;,citation_publication_date=2024-07-08;,citation_cover_date=2024-07-08;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1001/jamanetworkopen.2024.22833;,citation_issue=7;,citation_doi=10.1001/jamanetworkopen.2024.22833;,citation_volume=7;,citation_journal_title=JAMA Network Open;">
<meta name="citation_reference" content="citation_title=Healthcare predictive analytics using machine learning and deep learning techniques: a survey;,citation_author=Mohammed Badawy;,citation_author=Nagy Ramadan;,citation_author=Hesham Ahmed Hefny;,citation_publication_date=2023-08-29;,citation_cover_date=2023-08-29;,citation_year=2023;,citation_fulltext_html_url=https://doi.org/10.1186/s43067-023-00108-y;,citation_issue=1;,citation_doi=10.1186/s43067-023-00108-y;,citation_volume=10;,citation_language=en;,citation_journal_title=Journal of Electrical Systems and Information Technology;">
<meta name="citation_reference" content="citation_title=Explainable Artificial Intelligence for Predictive Modeling in Healthcare;,citation_author=Christopher C. Yang;,citation_publication_date=2022-02-11;,citation_cover_date=2022-02-11;,citation_year=2022;,citation_fulltext_html_url=https://pmc.ncbi.nlm.nih.gov/articles/PMC8832418/;,citation_issue=2;,citation_doi=10.1007/s41666-022-00114-1;,citation_volume=6;,citation_language=en;,citation_journal_title=Journal of Healthcare Informatics Research;">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Deep Learning Paper Review</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Author</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Shauna Heron </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Laurentian University
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      <div class="quarto-alternate-formats"><div class="quarto-title-meta-heading">Other Formats</div><div class="quarto-title-meta-contents"><p><a href="index.pdf"><i class="bi bi-file-pdf"></i>Typst</a></p></div></div></div>
    </div>



    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction-and-motivation" id="toc-introduction-and-motivation" class="nav-link active" data-scroll-target="#introduction-and-motivation">Introduction and Motivation</a></li>
  <li><a href="#problem-modeling-ehr-data-to-predict-crisis" id="toc-problem-modeling-ehr-data-to-predict-crisis" class="nav-link" data-scroll-target="#problem-modeling-ehr-data-to-predict-crisis">Problem: modeling EHR data to predict crisis</a></li>
  <li><a href="#solution-a-hybrid-model" id="toc-solution-a-hybrid-model" class="nav-link" data-scroll-target="#solution-a-hybrid-model">Solution: a hybrid model</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a>
  <ul class="collapse">
  <li><a href="#performance-comparison-across-models" id="toc-performance-comparison-across-models" class="nav-link" data-scroll-target="#performance-comparison-across-models">Performance Comparison Across Models</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#critical-analysis" id="toc-critical-analysis" class="nav-link" data-scroll-target="#critical-analysis"><strong>Critical Analysis</strong></a></li>
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"></a></li>
  </ul>
<div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="Presentation-1-preview.html"><i class="bi bi-journal-code"></i>Untitled</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<section id="introduction-and-motivation" class="level1">
<h1>Introduction and Motivation</h1>
<p>This review analyzes a study by <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>, published in <em>Cell Medical</em>, titled <em>“Combining Clinical Notes with Structured Electronic Health Records Enhances the Prediction of Mental Health Crises.”</em> The research investigates the utility of combining unstructured clinical notes with structured data from electronic health records (EHR) to improve the prediction of mental health crises <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>.</p>
<p>The relevance of the research is underscored by a global rise in mental health-related hospitalizations coinciding with significant workforce challenges <span class="citation" data-cites="roumeliotis2024 addressi2022"><a href="#ref-roumeliotis2024" role="doc-biblioref">[2]</a>, <a href="#ref-addressi2022" role="doc-biblioref">[3]</a></span>. Combined, these challenge stress the need for tools that might anticipate demand so that caseloads can be managed more efficiently. Even in Ontario, recent data highlights that hospitalizations for mental health conditions, particularly among youth, have surged since the COVID-19 pandemic <span class="citation" data-cites="addressi2022 roumeliotis2024"><a href="#ref-roumeliotis2024" role="doc-biblioref">[2]</a>, <a href="#ref-addressi2022" role="doc-biblioref">[3]</a></span>. With those requiring hospitalization (e.g., emotional breakdowns, substance overdoses and suicide attempts) increasing by 90% <span class="citation" data-cites="addressi2022"><a href="#ref-addressi2022" role="doc-biblioref">[3]</a></span>–many of which might have been prevented with early intervention, underscoring the idea that a tool that could predict the onset of mental health crises before they peak might conserve human resources as well as save lives <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>.</p>
</section>
<section id="problem-modeling-ehr-data-to-predict-crisis" class="level1">
<h1>Problem: modeling EHR data to predict crisis</h1>
<p>As the authors point out, leveraging EHRs to bolster clinical decision-making is not new <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>. Clinicians and researchers have long utilized structured data like diagnosis codes, lab results, and medication records to inform predictive models <span class="citation" data-cites="badawy2023"><a href="#ref-badawy2023" role="doc-biblioref">[4]</a></span>. However, computational limits as well as a lack of sophisticated modeling tools necessary to implement such models, meant that unstructured data like clinical notes and other free-form text, were most often left out of feature sets, despite the rich contextual information that clinical notes contain <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>.</p>
</section>
<section id="solution-a-hybrid-model" class="level1">
<h1>Solution: a hybrid model</h1>
<p>With this gap in mind, the authors proposed a hybrid solution that built on a previous study which used structured EHRs to predict crisis events with a weekly crisis-risk score <span class="citation" data-cites="garriga2022"><a href="#ref-garriga2022" role="doc-biblioref">[5]</a></span>, this time adding unstructured data in the form of clinical notes to bolster those predictions (2023). Specifically, the author’s hypothesized that models that combined both structured and unstructured data (such as clinical notes) would predict the probability of a weekly crisis event more accurately than a model including only structured data alone.</p>
<p>The structured data included static features like demographic information (e.g., postal code, race, gender), dynamic features like the most recent interactions with the hospital (e.g., substance use identified, new medication), and time-features that quantified the time that had elapsed since a specific event (e.g., time since the last crisis episode). Unstructured data was made up of free-form clinical notes written by clinicians. From these notes, semantic features were created using a BERT model, which is a pre-trained model good at extracting enhanced language features by considering the words that come before and after each word in a sentence <span class="citation" data-cites="bert101"><a href="#ref-bert101" role="doc-biblioref">[6]</a></span>.</p>
<p>Relying on those features four models were trained to predict a binary classification: relapse versus no relapse. The models included: i) a deep neural network trained on structured data (referred to as Struct DNN), ii) a model trained exclusively on unstructured data (Text DNN), iii) a hybrid model that integrated both structured and unstructured data (Hybrid DNN) and finally, iv) an ensemble of models that utilized predictions from the Hybrid DNN when unstructured data was available and predictions from the Struct DNN model otherwise (referred to as Ensemble DNN) was implemented. The experimental design and modeling process is outlined in <a href="#fig-modelflow" class="quarto-xref">Figure&nbsp;1</a>.</p>
<p><strong>Model Architecture and Data Flow Diagram</strong></p>
<div id="fig-modelflow" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-modelflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/paste-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Overview of the Hybrid DNN model and data input structure, showing how structured and unstructured data are processed. Adapted from [@garriga2023, pg. 3.]"><img src="images/paste-1.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-modelflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: <em>Overview of the Hybrid DNN model and data input structure, showing how structured and unstructured data are processed. Adapted from <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a>, pg. 3.</span></em>
</figcaption>
</figure>
</div>
<p>To address class imbalance issues (since crisis relapses are rare with only 1.3% prevalence), models were tuned to maximize the area under the precision-recall curve (AUPRC)–which as we learned in class is a particularly useful metric when evaluating results produced by imbalanced classes <span class="citation" data-cites="mc2024"><a href="#ref-mc2024" role="doc-biblioref">[7]</a></span>. Moreoever, as highlighted in our lessons, precision-recall metrics provide a better measure of a model’s predictive quality than accuracy in healthcare settings where false positives can be just as costly as false negatives <span class="citation" data-cites="mc2024 garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a>, <a href="#ref-mc2024" role="doc-biblioref">[7]</a></span>.</p>
<p>To evaluate model performance against non-machine learning methods used to evaluate crisis-risk, two baselines were built: a 5-factor logistic regression model informed by significant variables suggested in prior literature (LogReg5) and a heuristic model that ranked patients by the total number of crises they had experienced in the past year <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>.</p>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<p>The experiments revealed that the best structured data only model was an XGBoost classifier, a tree-based model implementing gradient boosting. The best performing model on unstructured data as well as combined structured and unstructured data was a feed-forward deep neural network (DNN) <span class="citation" data-cites="garriga2022"><a href="#ref-garriga2022" role="doc-biblioref">[5]</a></span>. The best performing model overall was an ensemble DNN that utilized predictions from a structured DNN when unstructured data was unavailable and the hybrid DNN combining data types when it was, enabling the model to draw insights from semantic features when available to increase overall performance <span class="citation" data-cites="garriga2022"><a href="#ref-garriga2022" role="doc-biblioref">[5]</a></span>.</p>
<p>Importantly, the authors also examined the impact that various features in the models had on predictive performance using Shapley additive explanations (SHAP) <span class="citation" data-cites="garriga2022 welcome"><a href="#ref-garriga2022" role="doc-biblioref">[5]</a>, <a href="#ref-welcome" role="doc-biblioref">[8]</a></span>. The authors use of SHAP to assess the predictive power of different types of data as well as different features is significant because it increased model interpretability and transparency which is critical in healthcare settings were decisions need to be trusted by front line staff <span class="citation" data-cites="yang2022"><a href="#ref-yang2022" role="doc-biblioref">[9]</a></span>. Though an in depth discussion of SHAP analysis is beyond the scope of this review, it is worth noting that the authors implemented it; allowing for both cohort-level and instance-specific explanations for predictions <span class="citation" data-cites="welcome"><a href="#ref-welcome" role="doc-biblioref">[8]</a></span>.</p>
<section id="performance-comparison-across-models" class="level2">
<h2 class="anchored" data-anchor-id="performance-comparison-across-models">Performance Comparison Across Models</h2>
<p>The comparative performance of the Structured-XGBoost, unstructured DNN and the hybrid DNN combining data types at predicting crisis in 10-week intervals across the 52 weeks are illustrated in the figure below.</p>
<p>According to the authors, the increase in AUPRC over time demonstrated in <strong>?@fig-AUPROC</strong> is only weakly related to an increase in EHR data over time, but instead more to the clinical fact that the chance of a crisis-relapse increases the longer a patient is in treatment <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>. The structured XGBoost model outperformed both models at 10-weeks, but at 20 weeks, when clinical note data becomes available, the XGBoost model is surpassed by the hybrid model. Higher AUPRC values indicate better precision in predicting true crisis-events relative to non-crisis events that are incorrectly predicted.</p>
<p><strong>AUPRC for Predictions Across 52 Weeks</strong></p>
<div id="fig-AUPRC" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-AUPRC-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/paste-3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;2: Precision-recall curves for the Hybrid DNN, Struct DNN, and Text DNN, in10-week intervals over 52 weeks show an increase in performance across all models over time. Adapted from [@garriga2023, pg. 5]"><img src="images/paste-3.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-AUPRC-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: <em>Precision-recall curves for the Hybrid DNN, Struct DNN, and Text DNN, in10-week intervals over 52 weeks show an increase in performance across all models over time. Adapted from <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a>, pg. 5</span></em>
</figcaption>
</figure>
</div>
<p>The receiver operating characteristic (AUROC) comparisons in <a href="#fig-AUROC" class="quarto-xref">Figure&nbsp;3</a> similarly reflects the model’s ability to distinguish between true positive and negative predictions, however AUROC is considered a more forgiving metric when evaluating imbalanced datasets because it measures the model’s overall capacity to separate classes, rather than focusing exclusively on predicting positive classes (crisis events) <span class="citation" data-cites="measurin2019"><a href="#ref-measurin2019" role="doc-biblioref">[10]</a></span>.</p>
<p>As indicated in <a href="#fig-AUROC" class="quarto-xref">Figure&nbsp;3</a>, the ability of both the structured XGBoost and unstructured DNN models to distinguish between classes <em>decreases</em> over time until 40 weeks when both the structured and hybrid model increase in performance. Interestingly, the performance of the unstructured-only model decreases across the entire 52 weeks, which the authors suggest highlights the complexity of modelling mental health crises: while the quantity of data in a given client file tends to increase over time, the overall number of patients requiring treatment <em>decreases</em> which impacts performance of the neural network (i.e., text input tends to require more examples or training instances to perform adequately in NNs) <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>.</p>
<p>Note too how the structured-only xgboost is best at predicting crisis with fewer than 10% of notes, but with 20% of weeks with available notes, the hybrid model’s performance offers a small improvement on performance, indicating that the addition of unstructured data helped the model make more accurate predictions across a range of thresholds, improving its overall discriminatory power.</p>
<p>Importantly, the best AUPRC scores averaged 0.23, which was above the baseline positive class rate of 1.3% for crisis relapse, indicating the models were better at predicting crisis onset than chance alone <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>. Moreoever, the AUROC scores averaged 0.87 for the best model which was significantly higher than the chance threshold for a binary classification at 0.5.</p>
<p><strong>AUROC Scores for Predictions Across 52 weeks</strong></p>
<div id="fig-AUROC" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-AUROC-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/paste-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure&nbsp;3: Performance of the Hybrid model compared to the unstructured and structured only models in predicting crisis episodes at 10 week intervals. Points and lines indicate mean and ± standard deviation values computed in the 52 weeks of the test set. Adapted from [@garriga2023, pg. 5]"><img src="images/paste-4.png" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-AUROC-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: <em>Performance of the Hybrid model compared to the unstructured and structured only models in predicting crisis episodes at 10 week intervals. Points and lines indicate mean and ± standard deviation values computed in the 52 weeks of the test set. Adapted from <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a>, pg. 5</span></em>
</figcaption>
</figure>
</div>
<p>SHAP analysis found that while structured data features dominated the top individual predictors for mental health crisis prediction, unstructured data (such as clinical notes) carried substantial predictive value when combined <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>. Although no single unstructured feature was highly impactful on its own, together they contributed more significantly than structured data alone. SHAP also showed that the predictive power of both structured and unstructured data increased with the availability of clinical notes, highlighting the importance of including both data types for better model performance <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>. See <a href="#fig-SHAP" class="quarto-xref">Figure&nbsp;4</a>.</p>
<p><strong>Contribution of data type for the hybrid DNN at 10 week intervals</strong></p>
<div id="fig-SHAP" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-SHAP-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/Capture.PNG" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure&nbsp;4: The total absolute SHAP values for the Hybrid DNN for structured and unstructured feature categories extracted on the test set across the different datasets based on the percentage of notes available from the patients. Adapted from [@garriga2023, pg. 5]"><img src="images/Capture.PNG" class="img-fluid figure-img" width="483"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-SHAP-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: <em>The total absolute SHAP values for the Hybrid DNN for structured and unstructured feature categories extracted on the test set across the different datasets based on the percentage of notes available from the patients. Adapted from <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a>, pg. 5</span></em>
</figcaption>
</figure>
</div>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>In conclusion, the study effectively demonstrated that incorporating unstructured clinical notes alongside structured EHR data improved the ability to predict mental health crises. Importantly their findings underscore the potential for including qualitative clinical data in predictive models using a novel ensemble methodology that might be used to build flexible models that adapt based on the availability of data in the client record. Furthermore they demonstrated the utility of implementing feature analysis to increase interpretability and transparency of healthcare models. Future research could explore the generalizability of these findings to other domains within healthcare. In particular, it would be interesting to examine whether their methodology could be used to model EHR in community mental health settings where symptomology may not be as extreme and unstructured data types more varied. Another potential direction would be to try improving methods for natural language processing (NLP) to better extract meaningful insights from clinical notes, which might further enhance predictive performance.</p>
</section>
<section id="critical-analysis" class="level1">
<h1><strong>Critical Analysis</strong></h1>
<p>All things considered, the paper offered a compelling case for the inclusion of unstructured data to bolster predictive modeling of healthcare data. The paper was particularly interesting to in the context of my own research where I aim to utilize structured EHR to predict case complexity in a community based mental health care agency. Importantly, they demonstrated and discussed several less common techniques, including a flexible ensemble approach to modeling that adapts depending on data availability <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>. In addition, they shared an in-depth SHAP feature analysis which allowed both cohort-level and instance-specific analysis critical for enhancing transparency in healthcare machine learning models <span class="citation" data-cites="badawy2023"><a href="#ref-badawy2023" role="doc-biblioref">[4]</a></span>. This was a fascinating component that I could have written a paper on all on its own.</p>
<p>While the paper was impressive overall, with many topics we could have explored further, the performance achieved by even the best model was modest at best. While the AUPRC and AUROC scores were notable in the context of predicting a rare event like a mental health crises, the results still reflect a gap between predictive performance and the reliability needed for clinical decision-making <span class="citation" data-cites="badawy2023"><a href="#ref-badawy2023" role="doc-biblioref">[4]</a></span>. The scores tells us that while the model can identify crises better than random guessing, the model may still flag many non-crisis events that could potentially overburden clinicians <span class="citation" data-cites="garriga2023"><a href="#ref-garriga2023" role="doc-biblioref">[1]</a></span>. A more thorough discussion of the model’s threshold for clinical utility would have been good to see and is perhaps in the works. In their earlier study they conducted a cohort study afterward to examine clinical utility in everyday practice which would be nice to see here too <span class="citation" data-cites="garriga2022"><a href="#ref-garriga2022" role="doc-biblioref">[5]</a></span>.</p>
<p>Overall the paper was very strong in terms of communicating the results in a way that was digestible and straightforward. The language was not jargony, there were very few complicated equations and the supplementary materials were robust and detailed. Whether it was the Python code used for each stage of the model building process or more in depth explanation of methodology, including tables of predictions and outcome metrics–all were included in the supplementary materials. In terms of its reproducibility the paper was excellent and will prove extremely useful for anyone hoping to use their methodology as a springboard for future research–which I hope to do!</p>
</section>
<section id="section" class="level1 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-garriga2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">R. Garriga, T. S. Buda, J. Guerreiro, J. O. Iglesias, I. E. Aguerri, and A. Matić, <span>“Combining clinical notes with structured electronic health records enhances the prediction of mental health crises,”</span> <em>Cell Reports Medicine</em>, vol. 4, no. 11, Nov. 2023, doi: <a href="https://doi.org/10.1016/j.xcrm.2023.101260">10.1016/j.xcrm.2023.101260</a>.</div>
</div>
<div id="ref-roumeliotis2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">N. Roumeliotis <em>et al.</em>, <span>“Mental health hospitalizations in canadian children, adolescents, and young adults over the COVID-19 pandemic,”</span> <em>JAMA Network Open</em>, vol. 7, no. 7, p. e2422833, Jul. 2024, doi: <a href="https://doi.org/10.1001/jamanetworkopen.2024.22833">10.1001/jamanetworkopen.2024.22833</a>.</div>
</div>
<div id="ref-addressi2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">CMHO, <span>“Addressing urgent workforce challenges in child and youth mental health,”</span> Mar. 2022.</div>
</div>
<div id="ref-badawy2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">M. Badawy, N. Ramadan, and H. A. Hefny, <span>“Healthcare predictive analytics using machine learning and deep learning techniques: a survey,”</span> <em>Journal of Electrical Systems and Information Technology</em>, vol. 10, no. 1, p. 40, Aug. 2023, doi: <a href="https://doi.org/10.1186/s43067-023-00108-y">10.1186/s43067-023-00108-y</a>.</div>
</div>
<div id="ref-garriga2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">R. Garriga <em>et al.</em>, <span>“Machine learning model to predict mental health crises from electronic health records,”</span> <em>Nature Medicine</em>, vol. 28, no. 6, pp. 1240–1248, Jun. 2022, doi: <a href="https://doi.org/10.1038/s41591-022-01811-5">10.1038/s41591-022-01811-5</a>.</div>
</div>
<div id="ref-bert101" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline"><span>“BERT 101 - state of the art NLP model explained.”</span> Available: <a href="https://huggingface.co/blog/bert-101">https://huggingface.co/blog/bert-101</a></div>
</div>
<div id="ref-mc2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">M. C. Lau, <span>“Machine Learning / Deep Learning - Classifier Evaluation Slides.”</span> Laurentian University, 2024.</div>
</div>
<div id="ref-welcome" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline"><span>“Welcome to the SHAP documentation <span></span> SHAP latest documentation.”</span> Available: <a href="https://shap.readthedocs.io/en/latest/">https://shap.readthedocs.io/en/latest/</a></div>
</div>
<div id="ref-yang2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">C. C. Yang, <span>“Explainable Artificial Intelligence for Predictive Modeling in Healthcare,”</span> <em>Journal of Healthcare Informatics Research</em>, vol. 6, no. 2, p. 228, Feb. 2022, doi: <a href="https://doi.org/10.1007/s41666-022-00114-1">10.1007/s41666-022-00114-1</a>.</div>
</div>
<div id="ref-measurin2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline"><span>“Measuring Performance: AUPRC and Average Precision.”</span> Mar. 02, 2019. Available: <a href="https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/">https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/</a></div>
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"loop":false,"openEffect":"zoom","descPosition":"bottom","selector":".lightbox","closeEffect":"zoom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>